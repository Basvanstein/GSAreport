{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from deap import benchmarks\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from SALib.sample import saltelli,finite_diff, fast_sampler, latin\n",
    "from SALib.analyze import morris,sobol, dgsm, fast, delta, rbd_fast\n",
    "from SALib.util import read_param_file\n",
    "from SALib.sample.morris import sample\n",
    "from SALib.plotting.morris import horizontal_bar_plot, covariance_plot, sample_histograms\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Import seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# Apply the default theme\n",
    "sns.set_theme()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def meanAbsoluteError(sens, f, d):\n",
    "    #calculate average distance (euclidean) to end result per algorithm (/per dim)\n",
    "    labels = ['Morris','Sobol','Fast', \"RDB-Fast\", \"Delta\", \"DGSM\", \"R2\", \"Pearson\", \"RF\", \"Linear\"]\n",
    "    avg_sens = np.mean(sens, axis=1)\n",
    "    for i in np.arange(avg_sens.shape[1]):\n",
    "        absolute_errors = []\n",
    "        for j in np.arange(avg_sens.shape[2]):\n",
    "            #end result (highest sample) (samples, algs, dims)\n",
    "            end_res = avg_sens[-1,i,j]\n",
    "            absolute_error_j = np.abs(avg_sens[:-1,i,j] - end_res) / len(avg_sens[:-1,i,j])\n",
    "            absolute_errors.append(absolute_error_j)\n",
    "        \n",
    "        with open('mae.csv', mode='a') as file_:\n",
    "            file_.write(\"{},{},{},{}\".format(labels[i], f, d, np.mean(absolute_errors)))\n",
    "            file_.write(\"\\n\")  # Next line.\n",
    "        #print(f, d, labels[i], np.mean(absolute_errors))\n",
    "\n",
    "def plotSensitivity(x_samples, sens, conf, title=\"Sensitivity scores\", filename=\"\"):\n",
    "    #print(sens.shape, conf.shape) #3, 10, 5, 2 = sample_sizes, reps, algs, dim\n",
    "\n",
    "    avg_sens = np.mean(sens, axis=1)\n",
    "    avg_conf = np.mean(conf, axis=1)\n",
    "    std_sens = np.std(sens, axis=1)\n",
    "\n",
    "    #colors = ['tab:blue','tab:orange','tab:green','tab:purple','tab:brown']\n",
    "    LINE_STYLES = ['solid', 'dashed', 'dashdot', 'dotted']\n",
    "    NUM_STYLES = len(LINE_STYLES)\n",
    "    colors = sns.color_palette('husl', n_colors=avg_sens.shape[2])\n",
    "    labels = ['Morris','Sobol','Fast', \"RDB-Fast\", \"Delta\", \"DGSM\", \"R2\", \"Pearson\", \"RF\", \"Linear\"]\n",
    "    cols = labels\n",
    "    rows = ['X{}'.format(row) for row in range(avg_sens.shape[2])]\n",
    "\n",
    "    \"\"\" #figure per X\n",
    "    fig, axes = plt.subplots(avg_sens.shape[2], avg_sens.shape[1], sharey=True, figsize=[20,3*avg_sens.shape[2]])\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    for j in np.arange(avg_sens.shape[2]):\n",
    "        for i in np.arange(avg_sens.shape[1]):\n",
    "            axes[j,i].fill_between(x_samples, (avg_sens[:,i,j]-std_sens[:,i,j]), (avg_sens[:,i,j]+std_sens[:,i,j]), color=conf_colors[i], alpha=0.2 )\n",
    "            axes[j,i].fill_between(x_samples, (avg_sens[:,i,j]-avg_conf[:,i,j]), (avg_sens[:,i,j]+avg_conf[:,i,j]), color=colors[i], alpha=0.1 )\n",
    "            axes[j,i].plot(x_samples,avg_sens[:,i,j],color=colors[i], label = labels[i])\n",
    "            axes[j,i].set_xticks(x_samples)\n",
    "            axes[j,i].set_xscale('log', base=2)\n",
    "            #if i > 0:\n",
    "            axes[j,i].set_ylim([0.0,1.0])\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, int(avg_sens.shape[1]/2), sharey=True, figsize=[20,6])\n",
    "    fig.suptitle(title)\n",
    "    \n",
    "    for j in np.arange(avg_sens.shape[2]):\n",
    "        for i in np.arange(avg_sens.shape[1]):\n",
    "            axes[int(i/5),i%5].fill_between(x_samples, (avg_sens[:,i,j]-std_sens[:,i,j]), (avg_sens[:,i,j]+std_sens[:,i,j]), color=colors[j], alpha=0.2 )\n",
    "            axes[int(i/5),i%5].fill_between(x_samples, (avg_sens[:,i,j]-avg_conf[:,i,j]), (avg_sens[:,i,j]+avg_conf[:,i,j]), color=colors[j], alpha=0.1 )\n",
    "            axes[int(i/5),i%5].plot(x_samples,avg_sens[:,i,j],color=colors[j], linestyle=LINE_STYLES[j%NUM_STYLES] , label = 'X'+str(j))\n",
    "            axes[int(i/5),i%5].set_xticks(x_samples)\n",
    "            axes[int(i/5),i%5].set_xscale('log', base=2)\n",
    "            axes[int(i/5),i%5].set_ylim([0.0,1.0])\n",
    "            axes[int(i/5),i%5].set_title(labels[i])\n",
    "\n",
    "    lines_labels = [ax.get_legend_handles_labels() for ax in [axes[0,0]]]\n",
    "    lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "\n",
    "    #for ax, col in zip(axes, cols):\n",
    "    #    ax.set_title(col)\n",
    "\n",
    "    #for ax, row in zip(axes[:,0], rows):\n",
    "    #    ax.set_ylabel(row, rotation=0)\n",
    "\n",
    "    # finally we invoke the legend (that you probably would like to customize...)\n",
    "\n",
    "    fig.legend(lines, labels)\n",
    "    fig.tight_layout()\n",
    "    plt.tight_layout()\n",
    "    #plt.xlabel(\"sample size\")\n",
    "    #plt.ylabel(\"sensitivity index\")\n",
    "    plt.savefig(f\"{filename}.pdf\")\n",
    "    #plt.show()\n",
    "    plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab8af36c5d24c8db112654286f444a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a57833b2b0440ddb3e611404929ff23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0731898c58a14cb5bbefd403a7501e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/basvanstein/Repositories/XAI/env/lib/python3.8/site-packages/SALib/analyze/rbd_fast.py:108: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return D1 / V\n",
      "/Users/basvanstein/Repositories/XAI/env/lib/python3.8/site-packages/SALib/analyze/rbd_fast.py:108: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return D1 / V\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14187f3a5b24a4c844c306f49583f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gw/jbc6715s5l9gj5723dd89yxh0000gn/T/ipykernel_51764/1582557369.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfIDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mrunSensitivityExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Average Sensitivity Scores per Sample Size on F{f} D{dim}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"f{f}-d{dim}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#maybe add repetitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/gw/jbc6715s5l9gj5723dd89yxh0000gn/T/ipykernel_51764/1582557369.py\u001b[0m in \u001b[0;36mrunSensitivityExperiment\u001b[0;34m(dim, f, title, filename)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mz_latin\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_latin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mres_rbd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbd_fast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_latin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_latin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_to_console\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mres_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_latin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_latin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_to_console\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0malg_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_rbd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"S1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0malg_conf_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_rbd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"S1_conf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/XAI/env/lib/python3.8/site-packages/SALib/analyze/delta.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(problem, X, Y, num_resamples, conf_level, print_to_console, seed)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mX_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             S['delta'][i], S['delta_conf'][i] = bias_reduced_delta(\n\u001b[0m\u001b[1;32m     77\u001b[0m                 Y, Ygrid, X_i, m, num_resamples, conf_level)\n\u001b[1;32m     78\u001b[0m             \u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'S1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msobol_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/XAI/env/lib/python3.8/site-packages/SALib/analyze/delta.py\u001b[0m in \u001b[0;36mbias_reduced_delta\u001b[0;34m(Y, Ygrid, X, m, num_resamples, conf_level)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;34m\"\"\"Plischke et al. 2013 bias reduction technique (eqn 30)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_resamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0md_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/XAI/env/lib/python3.8/site-packages/SALib/analyze/delta.py\u001b[0m in \u001b[0;36mcalc_delta\u001b[0;34m(Y, Ygrid, X, m)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mY_ix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_ix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mfyc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'silverman'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mfy_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfy\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfyc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def runSensitivityExperiment(dim, f, title, filename):\n",
    "    fun, opt = bn.instantiate(f, iinstance=1)\n",
    "    problem = {\n",
    "    'num_vars': dim,\n",
    "    'names': ['X'+str(x) for x in range(dim)],\n",
    "    'bounds': [[-5.0, 5.0]] * dim\n",
    "    }\n",
    "    x_samples = [8,16,32,64,128,256,512,1024,2048,4096,8192] #,8192,16384 ,\n",
    "    results = []\n",
    "    conf_results = []\n",
    "    \n",
    "    for sample_size in tqdm(x_samples,position=1, leave=False):\n",
    "        rep_results = []\n",
    "        rep_conf_results = []\n",
    "        for rep in tqdm(np.arange(10),position=2, leave=False):\n",
    "            np.random.seed(rep)\n",
    "            alg_results = []\n",
    "            alg_conf_results = []\n",
    "            X_morris = sample(problem, N=sample_size, num_levels=4, optimal_trajectories=None)\n",
    "            z_morris =  np.asarray(list(map(fun, X_morris)))\n",
    "\n",
    "            res_morris = morris.analyze(problem, X_morris, z_morris,\n",
    "                                        conf_level=0.95,\n",
    "                                        print_to_console=False,\n",
    "                                        num_levels=4,\n",
    "                                        num_resamples=10,\n",
    "                                        seed=rep)\n",
    "\n",
    "            mu_star_fixed = np.asarray(res_morris[\"mu_star\"]) / np.sum(res_morris[\"mu_star\"])\n",
    "            mu_star_conf_fixed = np.asarray(res_morris[\"mu_star_conf\"]) / np.sum(res_morris[\"mu_star\"])\n",
    "\n",
    "            alg_results.append( mu_star_fixed)\n",
    "            alg_conf_results.append( mu_star_conf_fixed)\n",
    "\n",
    "            #Sobol\n",
    "            X_sobol = saltelli.sample(problem, N=sample_size, calc_second_order=True)\n",
    "            z_sobol =  np.asarray(list(map(fun, X_sobol)))\n",
    "            res_sobol = sobol.analyze(problem, z_sobol, print_to_console=False,seed=rep)\n",
    "            alg_results.append( np.asarray(res_sobol[\"S1\"]))\n",
    "            alg_conf_results.append( np.asarray(res_sobol[\"S1_conf\"]))\n",
    "            \n",
    "\n",
    "            #Fast\n",
    "            M = 4\n",
    "            while ((4 * M)**2 > sample_size):\n",
    "                M -= 1\n",
    "            if M > 0:\n",
    "                X_fast = fast_sampler.sample(problem, N=sample_size, M=M, seed=rep)\n",
    "                z_fast =  np.asarray(list(map(fun, X_fast)))\n",
    "                res_fast = fast.analyze(problem, z_fast, print_to_console=False,seed=rep)\n",
    "                alg_results.append( np.asarray(res_fast[\"S1\"]))\n",
    "                alg_conf_results.append( np.asarray(res_fast[\"S1_conf\"]))\n",
    "            else:\n",
    "                alg_results.append(np.zeros(mu_star_fixed.shape))\n",
    "                alg_conf_results.append(np.zeros(mu_star_fixed.shape))\n",
    "\n",
    "            #rbd #delta\n",
    "            X_latin = latin.sample(problem, N=sample_size)\n",
    "            z_latin =  np.asarray(list(map(fun, X_latin)))\n",
    "            res_rbd = rbd_fast.analyze(problem, X_latin, z_latin, print_to_console=False,seed=rep)\n",
    "            res_delta = delta.analyze(problem, X_latin, z_latin, print_to_console=False,seed=rep)\n",
    "            alg_results.append( np.asarray(res_rbd[\"S1\"]))\n",
    "            alg_conf_results.append( np.asarray(res_rbd[\"S1_conf\"]))\n",
    "            alg_results.append( np.asarray(res_delta[\"S1\"]))\n",
    "            alg_conf_results.append( np.asarray(res_delta[\"S1_conf\"]))\n",
    "\n",
    "            #dgsm\n",
    "            X_dgsm = finite_diff.sample(problem, N=sample_size)\n",
    "            z_dgsm =  np.asarray(list(map(fun, X_dgsm)))\n",
    "            res_dgsm = dgsm.analyze(problem, X_dgsm, z_dgsm, print_to_console=False)\n",
    "            \n",
    "            dgsm_fixed = np.asarray(res_dgsm[\"dgsm\"]) / np.sum(res_dgsm[\"dgsm\"])\n",
    "            alg_results.append( dgsm_fixed)\n",
    "            dgsm_conf_fixed = np.asarray(res_dgsm[\"dgsm_conf\"]) / np.sum(res_dgsm[\"dgsm\"])\n",
    "            alg_conf_results.append( dgsm_conf_fixed)\n",
    "\n",
    "\n",
    "            #R2 score\n",
    "            r2s = []\n",
    "            for col in range(X_latin.shape[1]):\n",
    "                r2 = r2_score(z_latin, X_latin[:,col])\n",
    "                r2s.append(r2)\n",
    "            r2_fixed = np.asarray(r2s) / np.sum(r2s)\n",
    "            alg_results.append(np.array(r2_fixed))\n",
    "            alg_conf_results.append(np.zeros(np.array(r2s).shape))\n",
    "\n",
    "            #Pearson Correlation\n",
    "            prs = []\n",
    "            for col in range(X_latin.shape[1]):\n",
    "                pr,_ = pearsonr(X_latin[:,col], z_latin)\n",
    "                prs.append(pr)\n",
    "            alg_results.append(np.abs(prs))\n",
    "            alg_conf_results.append(np.zeros(np.array(prs).shape))\n",
    "\n",
    "            #Random forest\n",
    "            forest = RandomForestRegressor(random_state=rep)\n",
    "            forest.fit(X_latin, z_latin)\n",
    "            importances = forest.feature_importances_\n",
    "            std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "            rf_fixed = np.asarray(importances) / np.sum(importances)\n",
    "            rf_conf_fixed = np.asarray(std) / np.sum(importances)\n",
    "            alg_results.append(rf_fixed)\n",
    "            alg_conf_results.append(rf_conf_fixed)\n",
    "\n",
    "            #linear model\n",
    "            reg = LinearRegression().fit(X_latin, z_latin)\n",
    "            coefs = reg.coef_\n",
    "            coefs_fixed = np.abs(np.asarray(coefs)) / np.sum(np.abs(coefs))\n",
    "            alg_results.append(coefs_fixed)\n",
    "            alg_conf_results.append(np.zeros(coefs_fixed.shape))\n",
    "\n",
    "\n",
    "            #combine\n",
    "            rep_results.append(np.asarray(alg_results))\n",
    "            rep_conf_results.append(np.asarray(alg_conf_results))\n",
    "        results.append(np.asarray(rep_results))\n",
    "        conf_results.append(np.asarray(rep_conf_results))\n",
    "\n",
    "    plotSensitivity(x_samples, np.asarray(results), np.asarray(conf_results), title=title, filename=filename)\n",
    "    meanAbsoluteError(np.asarray(results), f, dim)\n",
    "\n",
    "from benchmark import bbobbenchmarks as bn\n",
    "\n",
    "fIDs = bn.nfreeIDs[:]    # for all fcts\n",
    "\n",
    "for dim in [2,5,10,20]:\n",
    "    for f in tqdm(fIDs, position=0):\n",
    "        runSensitivityExperiment(dim, f, title=f\"Average Sensitivity Scores per Sample Size on F{f} D{dim}\", filename=f\"f{f}-d{dim}\") #maybe add repetitions"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9437773fe6c237be7171778bcba0c7759da050030b102fb7a560b046fc790b67"
  },
  "kernelspec": {
   "display_name": "3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
